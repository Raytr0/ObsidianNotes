### When do we need to run the scheduler?
Nonpreemptive or cooperative scheduling. Because a process voluntarily game up the CPU. Scheduler did not have to preempt a process.
	• A process just switched from Running -> Wait. And you need to decide which process (from the ready queue) to run next. 
	• Process switched Running -> Terminate. And you need to decide which process (from the ready queue) to run next.
Preemptive scheduling. Because the scheduler might need to preempt a process. This is the defacto method.
• A process just switched from Running -> Ready (and you need to decide whether to run this process or a different one from the ready queue). 
• Process switched Waiting -> Ready (and you need to decide whether to run this process or a different one from the ready queue)

### What criteria should we use for designing our scheduling algorithms?
CPU utilization
	• Keeping CPU busy at all times. 
Throughput
	• How many processes are getting completed per time unit? 
Turnaround time
	• How long on average are the processes taking to complete from submission to completion? 
Waiting time
	• How long on average are the processes spending on the ready queue? 
Response time
	• How long before a process can produce its first response to the user?

### First Come First Serve (FCFS)
Non preemptive. Simplest of all; a FIFO queue. Just put incoming ready PCBs in the tail, and pull next process from head into ‘running’ state.![[Pasted image 20250302230712.png]]
![[Pasted image 20250302230736.png]]
Shorter processes will always have to wait for a big CPU bound process, impacting the wait time.

### Shortest Job First (SJF) Non-preemptive version.
• Each process is associated with the length of the process’s next CPU burst. 
• The algorithm chooses the shortest process to move from ready to running, breaking ties with FCFS.
![[Pasted image 20250302230928.png]]
This needs the length of the next CPU burst, but how can we know this?
Through Exponential averaging.
![[Pasted image 20250302231309.png]]
![[Pasted image 20250302231336.png]]

### Shortest Job First (SJF) Preemptive version.
• What will happen if there is a new process arrive in the ready queue with shorted burst time while there is already a process running? 
• Non-preemptive version will do nothing. Only re-run the algorithm after the current process is done executing (voluntarily release the CPU). 
• Pre-emptive version will re-run the algorithm when the new process arrives, and move that process to running and the running process to ready. (Can be renamed to shortest remaining time first.)
![[Pasted image 20250302231541.png]]

### Round-Robin (RR) scheduling
• Every process in FCFS is preempted after a fixed time slice quanta (10-100ms). The process is then placed at the end of the ready queue. 
• The ready queue is implemented as a circular queue.
![[Pasted image 20250302231637.png]]
![[Pasted image 20250302231655.png]]

### Priority scheduling
• Each process is assigned a priority number. E.g Windows [31-0], POSIX [0-139]. Processes with same priority are scheduled based on FCFS.
![[Pasted image 20250302231739.png]]
• Priority based scheduling is really flexible from the perspective of the OS. SJF can be thought as one type of priority scheduling. 
• The OS can use man different criteria to assign priorities internally, e.g., memory requirements, number of open files, any internal metric.
• However, there is a big problem with priority scheduling. 
• Starvation: If there are always higher priority processes arriving, a lower priority process can be in the ready queue forever!

### Round Robin + Priority (Multilevel queue)
![[Pasted image 20250302232109.png]]
• Remember, in one-to-one/many-to-many mapping, the OS kernel provides support for threading through kernel-level threads. 
• Two uses of the kernel level threads: 
	• a. When user level threads make system calls, they are assigned a kernel level thread for doing the job (I/O for example) 
	• b. The OS might want to manage it’s own processes through a kernel level multithreaded approach.
• For the purposes of scheduling, the user application can have it’s own scheduler that schedules the user threads into the kernel level threads 
• And the OS’s scheduler schedules the Kernel level threads. 
• In some OS, this mapping between user and kernel level threads are achieved through a specialized data structure known as LWP (Light Weight Processes). 
• And in such cases, the OS provides a ‘notification’ of sort (scheduler activation) to the application’s thread scheduler so that the kernel’s scheduler and the thread library scheduler is coordinated.
![[Pasted image 20250302234900.png]]

### Scheduling for Real-Time OS (RTOS)
Real time scheduling is all about dealing with latencies
• Soft real-time systems: Provides no guarantee when the critical process will be running. Only guarantee that the process will be given preference over non-critical processes. 
• Hard real-time systems: Comes with a time guarantee. The critical process must go into running before a specified deadline. 
• Admission control: The design philosophy of real time scheduling is declare upfront what you can and cannot guarantee. If a process cannot be serviced within it’s required deadline — reject that process even before admitting it in the ready queue.
![[Pasted image 20250303001944.png]]

Remember the steps involves in process context switch?
•When an interrupt is triggered (timer interrupt, I/O interrupt), the hardware first performs some housekeeping activity (all in preparation for the kernel to take over). 
•On the hardware side: 
	•Saves the basic registers, such as Program Counter, Program Status Word etc., onto the kernel stack. 
	•Interrupt Vector Table (IVT) has a map of the interrupt class to an address of the Interrupt Service Routine. 
	•The CPU jumps to the address pointed in the ISR and switches to the OS kernel mode (by setting a privilege bit in PSW register). 
	![[Pasted image 20250303002119.png]]
Dispatch Latency. Time that elapses from when the ISR is invoked to when the responding process starts running
	•The kernel then executes the ISR, which often saves further information about the process (represented in the PCB). •This is implemented in assembly language code (because you cannot save registers in C++) 
	•ISR’s job is more or less complete at this point and the control moves to scheduler to decide which process to execute next. 
	•Then the dispatcher comes into play. Registers from the PCB of the process to be running next is then loaded onto the hardware. Move to user mode, and start executing the new process from the PC (Program Counter) of the new process.

### Real time scheduling algorithm
• Admission control: The design philosophy of real time scheduling is declare upfront what you can and cannot guarantee. If a process cannot be serviced within it’s required deadline — reject that process even before admitting it in the ready queue. 
• Real time scheduling needs more information from the processes to do all this. 
• How often will a process need the CPU, i.e., the period (p). 
• The fixed processing time it needs to be running and utilizing the CPU (processing time, t) • A deadline (d) by when the process must be serviced.
![[Pasted image 20250303010531.png]]
### Rate monotonic scheduling
• It is preemptive (lower priority processes get preempted by higher priority processes). 
• It is priority based. Processes with higher periodic demand rate (1/p) is assigned higher priority. Priority stays static.  • Start with the information about period , processing time , and deadline of all processes whenever you need to run the scheduler. • Assign priority based on the periodic demand rate for all process. 
• Then estimate the scheduling viability with respected to these information.
![[Pasted image 20250303010655.png]]
![[Pasted image 20250303010710.png]]
![[Pasted image 20250303010736.png]]
