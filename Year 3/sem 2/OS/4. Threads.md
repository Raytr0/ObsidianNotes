![[Pasted image 20250302211332.png]]
Dispatcher process listens to incoming requests in an infinite loop. Then ‘dispatches’ the request to another worker process, which then reads and serves a file from the cache as a response.

We know that process creation takes up a lot of resources (context switch), therefore the improvement is to switch it to threads

### Threads
• The process model we discussed till now can be organized based on two independent concepts:
• Resource ownership/grouping: The address space (instruction + data) that process holds in memory. The resource management part — CPU, I/O, files, etc. assigned to a process by the OS.
• Execution life cycle: Anything to do with the ‘live’ aspect of the process, that is, how it moves through the life cycle. From creation to assigning it the CPU cycles, to blocking, and termination. And the way OS manages these life cycle.
• Threads provides a framework to separate out these two concepts.

### Multithreading
• The unit of resource ownership/grouping is the process. 
• The unit of execution life cycle is the thread. 
• Separating these out can lead to a paradigm where we have many different possible mapping between processes and threads.

### Process and Threads distinction
• In the context of allocation and management, some things are held and managed at the process level and some are held and managed at the thread level. 
• Process level concepts: The virtual address space. Protected access to processors, other processes for IPC, files, I/O resources. 
• Thread level concepts: The execution state, the PC, execution stack, thread context and thread level variables.
![[Pasted image 20250302211713.png]]
![[Pasted image 20250302211728.png]]

### Pros of Threads
• Performance: It takes much less time to create Threads compared to Processes (~10 times faster). Similarly, much less time to terminate, do context switch between threads, communicate between threads. 
• Responsiveness: If one thread is blocked, that does not block other threads interacting with the user. 
• Resource sharing: No need for fancy IPC mechanisms. 
• Scalability: Through threading, a single process can run parallel on multiple cores of the processor.

### Thread management
User mode to Kernel mode switch-overs in a multithreaded system 
• Remember, we discussed that during the life cycle of a process, the process regularly changes from user mode to kernel mode depending on the system calls it makes. 
• We can ask ourselves, how can that now work with different threads within a process. What if one thread makes a system call and moves to blocked state. What happens to the other threads in the process? Do they get blocked too?? 
• So you can see that there are two aspects to think through here: 
	• User —> Kernel mapping for system calls: How are user level threads mapped to the kernel process? (This depends on whether the kernel itself is multithreaded or not.) 
	• Thread state management: How can we manage the states of the threads similar to how we managed the states of the processes. After all, cheap context switch is a key advantage of threads, right?

![[Pasted image 20250302214024.png]]
Many different design possibilities: Many to one mapping (JVM); One to one mapping (Linux, Windows); Many to many mapping (Solaris). Thread state management will be implemented differently in each of these approaches.

### Thread Management at User Level
How can we prevent the entire process getting blocked due to one thread (especially since there are other threads that can be run?) 
• Solution is — Jacketing. 
• A special application level code take care of any I/O call. 
• It first checks (without a blocking system call) whether the I/O device is busy. 
• If it is, then at the user level, switch to another thread and blocking the thread that made the call. 
• The process stays in the running state throughout.

### Kernel level threads
One-to-one model
• In this paradigm, the multithreaded model is managed by the kernel. 
• E.g., POSIX (Linux, MacOS), Windows, all expose APIs for thread creation and management. Very similar to process creation and management. 
• Scheduling is performed at the level of threads instead of the level of processes.

### User level thread (N: 1)
• ULT advantages 
	• Fast — no kernel mode switch. 
	• Scheduling can be left to the application developers (domain specific scheduling). 
	• Can be supported on any OS.
• Disadvantages: 
	• Cannot take benefit of multiprocessor architecture. 
	• Complex jacketing code for converting blocking system calls to non blocking ones.

### Kernel level thread (1:1)
• KLT advantages 
	• Kernel can schedule multiple threads into multiple processors (if available). 
	• No need for jacketing code.
• Disadvantages
	• Requires mode switch to kernel mode for thread management.

### POSIX Threads API
![[Pasted image 20250302223056.png]]

### So…multithreaded or multiprocess programs? What should you do.
• Multithreading for lot of shared data to make use of low overhead. 
• Multiprocessing when you need isolation and fault tolerance. Crashing one thread will crash your entire process. 
• CPU bound tasks: Multiprocess. Make use of multiple cores. 
• I/O bound tasks: Multithreaded. Again, makes good use of CPU cycles. 
• Simplicity: Use multithreaded, if that will do the job well. It is easier to manage in a single application context.