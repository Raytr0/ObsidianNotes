### Process queues
• Most process state management is done by the scheduler (a special program within the kernel) by maintaining process queues. 
• Implemented as a linked list structure.![[Pasted image 20250302184002.png]]
![[Pasted image 20250302184012.png]]
• Once the process is created, it waits in the ready queue for the dispatcher to assign it a CPU core. 
• There may be a limit on the size of the ready queue (depending on virtual memory size) 
• Once it has been allotted CPU time, from there on, it can be moved to 
	• I/O wait queue (from I/O request) 
	• Child termination wait queue (if it spawns a child process) 
	• Interrupt wait queue (time slice expiry) Separating out wait queues avoids searching through a one big queue when an event occurs to move the appropriate process to ready state

### Process state transitions
• Null -> New : On process creation
• New -> Ready : When there is space available on ready queue.
• Ready -> Running : When it is time (based on the scheduler)
• Running -> Terminated : On process completion (or other reasons for exit)
• Running -> Ready : On process pre-emption. E.g., Expiry of time slice; higher priority process is in ready state.
• Running -> Blocked : Often on I/O request.
• Blocked -> Ready: Events such as I/O is done; resource is available.
![[Pasted image 20250302184317.png]]

### Key process creation steps
• Assign Process Identifier:
	• Generate a unique ID for the new process.
	• Add a new entry to the global process table (one entry per process).
• Allocate Process Space:
	• Allocate memory for the process image.
		• Program, data space (refer to previous slides on what a process space contains).
		• If there is shared space — that needs to be set up (you will see this in shared memory section)
• Allocate space for the Process Control Block (PCB).
	• Initialize PCB with the available information at creation time.
		• Process ID and parent process ID.
		• Processor State information
		• Program Counter (set to entry point).
		• Stack pointers (set to define boundaries).
• Set any control information about the state, etc.
	• State: Initialized to "Ready" or "Ready/Suspend."
	• Priority: Default to lowest unless specified.
	• Resources: Set based on inheritance or explicit request.
• Set linkages that will help manage the process by the OS:
	• Add the process to the appropriate scheduling queue, for example. Example: Ready or Ready/Suspend list (e.g., linked list structure).

### Process context switch
• Implementation of process context switch happens primarily through an interrupt mechanism. 
• PCB contains ALL information necessary to execute the process at a later stage.
![[Pasted image 20250302184915.png]]

### Process context switch steps
![[Pasted image 20250302185100.png]]
• When an interrupt is triggered (timer interrupt, I/O interrupt), the hardware first performs some housekeeping activity (all in preparation for the kernel to take over).
• On the hardware side:
• Saves the basic registers, such as Program Counter, Program Status Word etc., onto the kernel stack.
• Interrupt Vector Table (IVT) has a map of the interrupt class to an address of the Interrupt Service Routine.
• The CPU jumps to the address pointed in the ISR and switches to the OS kernel mode (by setting a privilege bit in PSW register).
• The kernel then executes the ISR, which often saves further information about the process (represented in the PCB).
• This is implemented in assembly language code (because you cannot save registers in C++)
• ISR’s job is more or less complete at this point and the control moves to scheduler to decide which process to execute next.
• Then the dispatcher comes into play. Registers from the PCB of the process to be running next is then loaded onto the hardware. Move to user mode, and start executing the new process from the PC (Program Counter) of the new process.

### I/O and CPU bound processes
• Remember, the point of multiprogramming is about CPU utilization. 
• I/O activities are orders of magnitude slower than computation. But I/O is indispensable to processes. 
• It is useful to characterize processes as two types based on their resource requirements: 
	• I/O bound: Processes that spend most of their time waiting for I/O operations interleaved with short CPU burst cycles. 
	• CPU bound: Processes that spend most of the time in computation with brief periods of I/O.

### A model for CPU utilization
• Let’s assume a process can either be waiting for I/O (probability p) or running (probability 1-p). 
• If there are n processes in memory, the probability that all of them are waiting for I/O (CPU is idle) is p^n
• n is the degree of multiprogramming. 
• Therefore, probability that CPU is not idle is 1 - p^n
• CPU utilization = 1 - p^n

### A model of CPU utilization
![[Pasted image 20250302185643.png]]
If we want 80% CPU utilization and our processes spend their time on I/O with probability 0.8, what is the degree of multiprogramming we need to support?

### How can we increase the degree of multiprogramming?
• Increasing the degree of multiprogramming requires increasing the size of main memory.
	• But, remember induced demand?
	• Alternate solution: Virtual memory.
		• Memory that is directly addressable by the OS. The size of virtual storage is limited by the addressing scheme and by the amount of secondary memory available and not by the actual main memory size.
		• Gives processes the illusion of having a large, contiguous memory space, even though the physical memory (RAM) may be much smaller.
• New problem: swapping processes in and out of main memory.
• How does this change the process state machine?
![[Pasted image 20250302185809.png]]

### Interprocess communication
• Till now, we were only dealing with processes as independent entities. But for most real systems, processes need to talk and cooperate with each other. 
• In that context, we can categorize processes as being either 
	• Independent processes: if it does not share data with any other processes executing in the system 
	• Cooperating process: if it can affect or be affected by the other processes executing in the system. 
• Why we need this? 
	• Information sharing 
	• Computational speedup (especially with multicore processors) 
	• Modularity by breaking system functions into separate processes.
![[Pasted image 20250302185840.png]]
![[Pasted image 20250302185901.png]]

### Shared memory implementation in POSIX
![[Pasted image 20250302185956.png]]![[Pasted image 20250302190004.png]]

### Microkernel OS execution
![[Pasted image 20250302185922.png]]
